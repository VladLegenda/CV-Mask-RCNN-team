{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325a8c3-e585-462c-b390-2afaabb08cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a3c9ca-d735-43e9-9f73-72e6fb0b4370",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/archive (3).zip\" -d /content/dataset1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24895abc-912b-45b7-8152-04a533d421eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.image_files = sorted(os.listdir(images_dir))\n",
    "        self.mask_files = sorted(os.listdir(masks_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Загружаем изображения и маски\n",
    "        image_path = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.mask_files[idx])\n",
    "\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        # Применение преобразований\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Преобразуем маску в тензор и убираем лишнюю размерность\n",
    "        mask = transforms.ToTensor()(mask)  \n",
    "        mask = mask.unsqueeze(0)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e909f01a-95ee-4eb8-a8a6-a247d3e60bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0e631-b630-41b6-9bca-1eb1f240db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути к папкам с изображениями и масками\n",
    "images_dir = '/content/dataset1/Forest Segmented/Forest Segmented/images'\n",
    "masks_dir = '/content/dataset1/Forest Segmented/Forest Segmented/masks'\n",
    "\n",
    "# Получаем список файлов\n",
    "image_files = sorted(os.listdir(images_dir))\n",
    "mask_files = sorted(os.listdir(masks_dir))\n",
    "\n",
    "\n",
    "train_images, valid_images, train_masks, valid_masks = train_test_split(\n",
    "    image_files, mask_files, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Создание датасетов\n",
    "train_dataset = SegmentationDataset(\n",
    "    images_dir=images_dir,\n",
    "    masks_dir=masks_dir,\n",
    "    transform=image_transform\n",
    ")\n",
    "\n",
    "valid_dataset = SegmentationDataset(\n",
    "    images_dir=images_dir,\n",
    "    masks_dir=masks_dir,\n",
    "    transform=image_transform\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Valid dataset size: {len(valid_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f365ef4-4573-4398-93c6-a8e94fc6452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e3757-a38a-4bb3-bd64-96f1374abb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install segmentation-models-pytorch torch torchvision scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2e096-e0fe-4aeb-9dd1-bb0470419552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка предобученной модели U-Net\n",
    "model = smp.Unet(\n",
    "    encoder_name='resnet50',        # Энкодер\n",
    "    encoder_weights='imagenet',    # Предобученные веса на ImageNet\n",
    "    in_channels=3,                 # Количество входных каналов (RGB = 3)\n",
    "    classes=1                      # Количество классов (для бинарной сегментации = 1)\n",
    ")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ff1c5-943c-4e54-9897-a83a1b89b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e50ee-79e2-4d41-af90-068192a92a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Функция для вычисления IoU\n",
    "def calculate_iou(true_mask, pred_mask):\n",
    "    intersection = np.sum(true_mask * pred_mask)\n",
    "    union = np.sum(true_mask) + np.sum(pred_mask) - intersection\n",
    "    return intersection / union if union != 0 else 0\n",
    "\n",
    "# Функция для вычисления Dice Coefficient\n",
    "def calculate_dice(true_mask, pred_mask):\n",
    "    intersection = np.sum(true_mask * pred_mask)\n",
    "    return (2.0 * intersection) / (np.sum(true_mask) + np.sum(pred_mask) + 1e-7)\n",
    "\n",
    "# Функция для вычисления Accuracy\n",
    "def calculate_accuracy(true_mask, pred_mask):\n",
    "    correct_pixels = np.sum(true_mask == pred_mask)\n",
    "    total_pixels = true_mask.size\n",
    "    return correct_pixels / total_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bf0d5b-b5d7-4058-b292-b46d146c5849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_iou = 0.0\n",
    "        train_dice = 0.0\n",
    "        train_accuracy = 0.0\n",
    "\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            outputs = outputs.unsqueeze(1)\n",
    "\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(outputs).detach().cpu().numpy() > 0.5\n",
    "            true_masks = masks.detach().cpu().numpy()\n",
    "\n",
    "            train_iou += np.mean([calculate_iou(true_mask, pred_mask)\n",
    "                                  for true_mask, pred_mask in zip(true_masks, preds)])\n",
    "            train_dice += np.mean([calculate_dice(true_mask, pred_mask)\n",
    "                                   for true_mask, pred_mask in zip(true_masks, preds)])\n",
    "            train_accuracy += np.mean([calculate_accuracy(true_mask, pred_mask)\n",
    "                                       for true_mask, pred_mask in zip(true_masks, preds)])\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "        valid_iou = 0.0\n",
    "        valid_dice = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, masks in valid_loader:\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                outputs = model(images)\n",
    "\n",
    "                outputs = outputs.unsqueeze(1)  # Добавляем размерность канала\n",
    "                loss = criterion(outputs, masks)\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                preds = torch.sigmoid(outputs).detach().cpu().numpy() > 0.5\n",
    "                true_masks = masks.detach().cpu().numpy()\n",
    "\n",
    "                valid_iou += np.mean([calculate_iou(true_mask, pred_mask)\n",
    "                                      for true_mask, pred_mask in zip(true_masks, preds)])\n",
    "                valid_dice += np.mean([calculate_dice(true_mask, pred_mask)\n",
    "                                       for true_mask, pred_mask in zip(true_masks, preds)])\n",
    "                valid_accuracy += np.mean([calculate_accuracy(true_mask, pred_mask)\n",
    "                                           for true_mask, pred_mask in zip(true_masks, preds)])\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_iou /= len(train_loader)\n",
    "        train_dice /= len(train_loader)\n",
    "        train_accuracy /= len(train_loader)\n",
    "\n",
    "        valid_loss /= len(valid_loader)\n",
    "        valid_iou /= len(valid_loader)\n",
    "        valid_dice /= len(valid_loader)\n",
    "        valid_accuracy /= len(valid_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Train Dice: {train_dice:.4f}, Train Accuracy: {train_accuracy:.4f}, \"\n",
    "              f\"Valid Loss: {valid_loss:.4f}, Valid IoU: {valid_iou:.4f}, Valid Dice: {valid_dice:.4f}, Valid Accuracy: {valid_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84bdba3-b769-47a2-9eb6-3b7b6563db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c5384-74da-4e17-a08f-8c71cd9ed3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/content/dataset1/Forest Segmented/Forest Segmented/images/114433_sat_60.jpg'\n",
    "mask_path = '/content/dataset1/Forest Segmented/Forest Segmented/masks/114433_mask_60.jpg'\n",
    "\n",
    "# Загрузка и предобработка изображения\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "# Загрузка истинной маски\n",
    "true_mask = Image.open(mask_path).convert(\"L\")  # Конвертация в оттенки серого\n",
    "true_mask = np.array(true_mask.resize((256, 256))) / 255  # Изменение размера и нормализация [0, 1]\n",
    "\n",
    "# Инференс\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)\n",
    "    pred_mask = torch.sigmoid(output).cpu().numpy()[0][0] > 0.5  # Бинаризация предсказания\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Исходное изображение\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Истинная маска\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(true_mask, cmap=\"gray\")\n",
    "plt.title(\"Ground Truth Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Предсказанная маска\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(pred_mask, cmap=\"gray\")\n",
    "plt.title(\"Predicted Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
